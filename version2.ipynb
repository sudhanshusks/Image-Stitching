{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the keypoints to stitch the images\n",
    "def get_stitched_image(img1, img2, M):\n",
    "\n",
    "    # Get width and height of input images\t\n",
    "    w1,h1 = img1.shape[:2]\n",
    "    w2,h2 = img2.shape[:2]\n",
    "\n",
    "    # Get the canvas dimesions\n",
    "    img1_dims = np.float32([ [0,0], [0,w1], [h1, w1], [h1,0] ]).reshape(-1,1,2)\n",
    "    img2_dims_temp = np.float32([ [0,0], [0,w2], [h2, w2], [h2,0] ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    # Get relative perspective of second image\n",
    "    img2_dims = cv2.perspectiveTransform(img2_dims_temp, M)\n",
    "\n",
    "    # Resulting dimensions\n",
    "    result_dims = np.concatenate( (img1_dims, img2_dims), axis = 0)\n",
    "\n",
    "    # Getting images together\n",
    "    # Calculate dimensions of match points\n",
    "    [x_min, y_min] = np.int32(result_dims.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(result_dims.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "    # Create output array after affine transformation \n",
    "    transform_dist = [-x_min,-y_min]\n",
    "    transform_array = np.array([[1, 0, transform_dist[0]], \n",
    "                                [0, 1, transform_dist[1]], \n",
    "                                [0,0,1]]) \n",
    "\n",
    "    # Warp images to get the resulting image\n",
    "    result_img = cv2.warpPerspective(img2, transform_array.dot(M), \n",
    "                                    (x_max-x_min, y_max-y_min))\n",
    "    result_img[transform_dist[1]:w1+transform_dist[1], \n",
    "                transform_dist[0]:h1+transform_dist[0]] = img1\n",
    "\n",
    "    # Return the result\n",
    "    return result_img\n",
    "\n",
    "# Find SIFT and return Homography Matrix\n",
    "def get_sift_homography(img1, img2):\n",
    "\n",
    "    # Initialize SIFT \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # Extract keypoints and descriptors\n",
    "    k1, d1 = sift.detectAndCompute(img1, None)\n",
    "    k2, d2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Bruteforce matcher on the descriptors\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(d1,d2, k=2)\n",
    "\n",
    "    # Make sure that the matches are good\n",
    "    verify_ratio = 0.8 # Source: stackoverflow\n",
    "    verified_matches = []\n",
    "    for m1,m2 in matches:\n",
    "        # Add to array only if it's a good match\n",
    "        if m1.distance < 0.8 * m2.distance:\n",
    "            verified_matches.append(m1)\n",
    "\n",
    "    # Mimnum number of matches\n",
    "    min_matches = 8\n",
    "    if len(verified_matches) > min_matches:\n",
    "        \n",
    "        # Array to store matching points\n",
    "        img1_pts = []\n",
    "        img2_pts = []\n",
    "\n",
    "        # Add matching points to array\n",
    "        for match in verified_matches:\n",
    "            img1_pts.append(k1[match.queryIdx].pt)\n",
    "            img2_pts.append(k2[match.trainIdx].pt)\n",
    "        img1_pts = np.float32(img1_pts).reshape(-1,1,2)\n",
    "        img2_pts = np.float32(img2_pts).reshape(-1,1,2)\n",
    "        \n",
    "        # Compute homography matrix\n",
    "        M, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, 5.0)\n",
    "        return M\n",
    "    else:\n",
    "        print ('Error: Not enough matches')\n",
    "        exit()\n",
    "\n",
    "# Equalize Histogram of Color Images\n",
    "def equalize_histogram_color(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return img\n",
    "\n",
    "# Main function definition\n",
    "def main():\n",
    "    \n",
    "    # Get input set of images\n",
    "    img1 = cv2.imread(\"rot2.jpg\")\n",
    "    img2 = cv2.imread(\"rot1.jpg\")\n",
    "    #img1= np.full(img1.shape, np.uint8)\n",
    "\n",
    "    # Equalize histogram\n",
    "    img1 = equalize_histogram_color(img1)\n",
    "    img2 = equalize_histogram_color(img2)\n",
    "\n",
    "    # Show input images\n",
    "    #input_images = np.hstack( (img1, img2) )\n",
    "    #cv2.imshow ('Input Images', input_images)\n",
    "\n",
    "    # Use SIFT to find keypoints and return homography matrix\n",
    "    M =  get_sift_homography(img1, img2)\n",
    "\n",
    "    # Stitch the images together using homography matrix\n",
    "    result_image = get_stitched_image(img2, img1, M)\n",
    "\n",
    "    # Write the result to the same directory\n",
    "    result_image_name = 'result.jpg'\n",
    "    cv2.imwrite(result_image_name, result_image)\n",
    "\n",
    "    # Show the resulting image\n",
    "    cv2.imshow ('result.jpg')\n",
    "    cv2.waitKey()\n",
    "\n",
    "# Call main function\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(\"result.jpg\")\n",
    "cv2.imshow ('result', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
